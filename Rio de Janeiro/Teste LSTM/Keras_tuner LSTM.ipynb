{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dados para pesca indsutrial de lulas (39 anos com dados)\n",
    "ano = np.array([1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022])\n",
    "pesca_ind = np.array([20,129,18,115,20,12,87,23,57,30,6,21,286,488.5,252.5,345.5,637.5,214,387.5,389.5,444,421.5,507,572.5,2.167,28.509,22.627,210.691,201.510,76.178,94.943,25.068,0.023,70.803,44.520,38.862,13.997,25.392,13.432])\n",
    "\n",
    "\n",
    "#Normalização dos dados\n",
    "ano_media = np.mean(ano)\n",
    "pi_media = np.mean(pesca_ind)\n",
    "\n",
    "ano_std = np.sqrt( np.sum((ano - ano_media)**2)/38  )\n",
    "pi_std = np.sqrt( np.sum((pesca_ind - pi_media)**2)/38  )\n",
    "\n",
    "ano_normalizado = (ano - ano_media)/ano_std\n",
    "pi_normalizado = (pesca_ind - pi_media)/pi_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colocando dados normalizados no formato de entrada da rede\n",
    "ano_normalizado = ano_normalizado.reshape((39,1))\n",
    "pi_normalizado = pi_normalizado.reshape((39,1))\n",
    "\n",
    "#Divisão entre teste e treino\n",
    "ano_treino,ano_teste,pi_treino,pi_teste = train_test_split(ano_normalizado,pi_normalizado, test_size=0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hipermodelo\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "      \n",
    "    for i in range(hp.Int('num_LSTM_layers',2,4,step=1)):\n",
    "      model.add(layers.LSTM(hp.Int(f'units_{i}',32,128,step=16), \n",
    "                             activation = hp.Choice('activation',['relu','leaky_relu','tanh','sigmoid']),\n",
    "                             dropout = hp.Float('drop_rate',0.1,0.25,sampling='log')))\n",
    "\n",
    "\n",
    "    for i in range(hp.Int('num_Dense_layers',2,3,step=1)):\n",
    "      model.add(layers.Dense(hp.Int(f'units_{i}',32,128,step=16), \n",
    "                             activation=hp.Choice('activation',['relu','leaky_relu','tanh','sigmoid'])))\n",
    "      if hp.Boolean('dropout'):\n",
    "         model.add(layers.Dropout(rate=hp.Float('drop_rate',0.1,0.25,sampling='log')))\n",
    "\n",
    "    model.add(layers.Dense(1,activation='linear'))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=hp.Choice('optimizer',['adam','sgd','Nadam']),\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
